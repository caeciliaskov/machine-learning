---
title: "miniTCGA prediction"
author: "LCP Soundsystem"
date: 'Last update: `r Sys.time()`'
output: 
  html_document:
    theme: united
    code_folding: show
    toc: true
editor_options: 
  chunk_output_type: inline
--- 

```{r}

# library(plyr)
library(tidyverse)
library(caret)
library(glmnet)


```

```{r}
# Reading the data:
df <- read_rds("../TCGA_cancer_classification/miniTCGA.3349x4006.rds") 

# Normalizing the data:
norm_df <- as.data.frame(scale(df[7:4006]))
norm_df <- cbind(df[1:6], norm_df)

```

# Quick view of all data

```{r}

norm_df[1:10,1:10]

```

# Split into training and prediction set

```{r}

data_train    <- norm_df %>% filter(!is.na(response))
data_predict  <- norm_df %>% filter(is.na(response))

```

# Finding predictors

```{r}

# Find the genes that are best at discriminating between types
best_genes <- pivot_longer(data_train, cols = 7:4006, names_to ="gene", values_to = "expression")

best_genes <- best_genes %>%
  group_by(gene, tissue) %>%
  summarise(mean_tumor = mean(expression[response == "Tumor"]), mean_normal = mean(expression[response == "Normal"]), mean_diff = abs(mean_normal - mean_tumor))

# As a big difference in means between normal and tumor means that there might be a bigger difference in expression whether the tissue is normal or tumor.

arrange(best_genes, desc(mean_diff))

```
# Finding the best model to predict

```{r}

set.seed(1)

# First we select 90% of the data and put their indicies in a vector
inTraining <- createDataPartition(data_train$response, p = .90, list = FALSE) # We use 90% of data for training

# Then we make a training data frame containing the 90 % of the data and a validation data frame with the 10% rest of the data
training    <- data_train[ inTraining,]
validation  <- data_train[-inTraining,]

# We then make a data frame containing the predictors and one containing the response
training_x <- training %>% select(AQP2.359, ACOT12.134526, GADL1.339896, FXYD4.53828, KCNJ1.3758, SLC9A4.389015, TDGF3.6998, PTGER1.5731, LOC284578.284578, FLRT1.23769, RS1.6247, GPA33.10223, RBP2.5948, LY6G6F.259215, ACVRL1.94, ANKRD1.27063, GINS1.9837, TMEM177.80775, ABCA3.21, CLEC3B.7123, AQP7P3.441432, ABCA10.10349, LOC415056.415056, LOC572558.572558, ANGPTL7.10218, LEP.3952, SYNM.23336, NAALAD2.10003, SLC19A3.80704, ABCA9.10350) %>% as.data.frame()

training_y <- training$response

# We make the cross validation
trControl <- trainControl(method = "repeatedcv", number = 5, repeats = 3, verboseIter = F)

fit <- train(x = training_x, 
               y = training_y, 
               method = "glmnet",
               tuneLength = 3,
               trControl = trControl)

```
# Test error

```{r}

# We predict on the test fold
predicted <- predict(fit, newdata = validation)
predicted <- levels(training$response)[predicted]

# We compare with the observed values and calculate error rate
observed    <- validation$response

# Our guess on the general error rate of the model (very unprecise!)
(test_error <- sum(observed!=predicted)/length(observed)) 

```

# Accuracy using cross validation

```{r}
cv_rmse <- function(x, k, r){
  train_control <- trainControl(method = "repeatedcv", number = k, repeats = r)
  model <- train(response ~ AQP2.359 + ACOT12.134526 + GADL1.339896 + FXYD4.53828 + KCNJ1.3758 + SLC9A4.389015 + TDGF3.6998 + PTGER1.5731 + LOC284578.284578 + FLRT1.23769 + RS1.6247 + GPA33.10223 + RBP2.5948 + LY6G6F.259215	+ ACVRL1.94 + ANKRD1.27063 + GINS1.9837 + TMEM177.80775 + ABCA3.21 + CLEC3B.7123 + AQP7P3.441432 + ABCA10.10349 + LOC415056.415056 + LOC572558.572558 + ANGPTL7.10218 + LEP.3952	+ SYNM.23336	+ NAALAD2.10003	+ SLC19A3.80704 + ABCA9.10350, data = x, method = "glm", trControl = train_control)
  return(model)
}

cv_rmse(data_train, 10, 10)

```

# Predict the real unknown data

First we fit the model to all of our known data

Then we predict on the unknown data

The predictions must have the following column and the row order must be the same as the original!

* predicted (the predicted class, either "Normal" or "Tumor")

```{r}
predicted <- predict(fit, newdata = data_predict)
predicted <- levels(data_train$response)[predicted]

submission <- tibble(predicted)

head(submission)

```
# Submitting your answer

The following code will give us

* your chosen team name
* the name of the people on the team
* your estimated error rate (from train/test or CV or similar)
* your predictions

Please edit the values below.

The filename of the output will be automated minitcga_cancer_classification.TEAMNAME.rds

Please - do not use space or funny letters in your team name.

```{r}

team_name        <- "LCPSoundsystem"
team_people      <- c("Peter", "CÃ¦cilia", "Lea")
team_error       <- test_error
team_predictions <- submission

#
# Always run this code
# If it fails you have done something wrong!
#
# Extract the columns needed
library(dplyr)
team_predictions <- subset(team_predictions, select = predicted)

# Save all the stuff in one object
write_rds(x = list(team_name, team_people, team_error, team_predictions), 
          file = paste("tcga_prediction_3_", team_name, ".rds", sep=""))

```

# Checking format of all saved objects

```{r}

files   <- Sys.glob("tcga_prediction_3_LCPSoundsystem.rds")
results <- tibble(filename = files, team_name = NA, team_people = NA, team_error = NA)

for (i in 1:nrow(results)) {
  x <- read_rds(file = as.character(results$filename[i]))
  results$team_name[i]     <- x[[1]]
  results$team_people[i]   <- paste(x[[2]], collapse=",", sep=" ")
  results$team_error[i]    <- x[[3]]
  y                        <- x[[4]]
  results$n_tumor          <- sum(y$predicted=="Tumor")
  results$n_normal         <- sum(y$predicted=="Normal")
}

rm(x,y)

results %>% select(-filename)

```

# Upload your rds file!
