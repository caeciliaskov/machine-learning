---
title: "miniTCGA prediction"
author: "LCP Soundsystem"
date: 'Last update: `r Sys.time()`'
output: 
  html_document:
    theme: united
    code_folding: show
    toc: true
editor_options: 
  chunk_output_type: inline
--- 

```{r}

# library(plyr)
library(tidyverse)
library(MASS)
library(caret)
library(ROCR)
library(class)
library(caTools)

```

```{r}
# Reading the data:
df <- read_rds("/Users/caeciliaskov-jensen/Documents/Uni/8. semester/Statistical and Machine Learning/16. Predictions/TCGA_cancer_classification/miniTCGA.3349x4006.rds") 

# Normalizing the data:
norm_df <- as.data.frame(scale(df[7:4006]))
norm_df <- cbind(df[1:6], norm_df)

```

# Quick view of all data

```{r}

norm_df[1:10,1:10]

```

# Split into training and prediction set

```{r}

set.seed(0)

data_train    <- norm_df %>% filter(!is.na(response))
data_predict  <- norm_df %>% filter(is.na(response))

```

# Finding predictors

```{r}

# Find the genes that are best at discriminating between types
best_genes <- pivot_longer(data_train, cols = 7:4006, names_to ="gene", values_to = "expression")

best_genes <- best_genes %>%
  group_by(gene, tissue) %>%
  summarise(mean_tumor = mean(expression[response == "Tumor"]), mean_normal = mean(expression[response == "Normal"]), mean_diff = abs(mean_normal - mean_tumor))

# As a big difference in means between normal and tumor means that there might be a bigger difference in expression whether the tissue is normal or tumor.

arrange(best_genes, desc(mean_diff))

```
# Finding the best model to predict

```{r}

# We fit our model
trainfold <- data_train %>% sample_frac(size = 0.8)
testfold <- setdiff(data_train, trainfold)

# Logistic regression:
fit1 <-  glm(response ~ AQP2.359 + RS1.6247 + AQP7P3.441432, data = trainfold, family=binomial(link='logit'))
fit1_predict <- predict(fit1, testfold)
fit1_rocpredict <- prediction(as.integer(fit1_predict), testfold$response)
fit1_performance <- performance(fit1_rocpredict, "tpr", "fpr")
fit1_auc <- as.numeric(performance(fit1_rocpredict, "auc")@y.values)

# LDA:
fit2 <-  lda(response ~ AQP2.359 + RS1.6247 + AQP7P3.441432, data = trainfold)
fit2_predict <- predict(fit2, testfold)$class
fit2_rocpredict <- prediction(as.integer(fit2_predict), testfold$response)
fit2_performance <- performance(fit2_rocpredict, "tpr", "fpr")
fit2_auc <- as.numeric(performance(fit2_rocpredict, "auc")@y.values)

# QDA:
fit3 <-  qda(response ~ AQP2.359 + RS1.6247 + AQP7P3.441432, data = trainfold)
fit3_predict <- predict(fit3, testfold)$class
fit3_rocpredict <- prediction(as.integer(fit3_predict), testfold$response)
fit3_performance <- performance(fit3_rocpredict, "tpr", "fpr")
fit3_auc <- as.numeric(performance(fit3_rocpredict, "auc")@y.values)

# Comparing the methods::
par(mfrow = c(2,2))
plot(fit1_performance, main = "ROC-curve for logistic regression")
plot(fit2_performance, main = "ROC-curve for LDA")
plot(fit3_performance, main = "ROC-curve for QDA")
# Looks like logistic regression is a better method.


```
# Test error

```{r}

# We predict on the test fold
predicted <- predict(fit1, newdata = testfold, type = "response")
predicted <- round(predicted)+1 # Convert probabilities to 0 or 1
predicted <- levels(trainfold$response)[predicted]

# We compare with the observed values and calculate error rate
observed    <- testfold$response

# Our guess on the general error rate of the model (very unprecise!)
(test_error <- sum(observed!=predicted)/length(observed)) 

```

# Accuracy using cross validation

```{r}
cv_rmse <- function(x, k, r){
  train_control <- trainControl(method = "repeatedcv", number = k, repeats = r)
  model <- train(response ~ AQP2.359 + RS1.6247 + AQP7P3.441432, data = x, method = "glm", trControl = train_control)
  return(model)
}

cv_rmse(data_train, 10, 10)

```

# Predict the real unknown data

First we fit the model to all of our known data

Then we predict on the unknown data

The predictions must have the following column and the row order must be the same as the original!

* predicted (the predicted class, either "Normal" or "Tumor")

```{r}
predicted <- predict(fit1, newdata = data_predict, type = "response")
predicted <- round(predicted)+1 # Convert probabilities to 1 or 2
predicted <- levels(data_train$response)[predicted]

submission <- tibble(predicted)

head(submission)

```
# Submitting your answer

The following code will give us

* your chosen team name
* the name of the people on the team
* your estimated error rate (from train/test or CV or similar)
* your predictions

Please edit the values below.

The filename of the output will be automated minitcga_cancer_classification.TEAMNAME.rds

Please - do not use space or funny letters in your team name.

```{r}

team_name        <- "LCPSoundsystem"
team_people      <- c("Peter", "CÃ¦cilia", "Lea")
team_error       <- test_error
team_predictions <- submission

#
# Always run this code
# If it fails you have done something wrong!
#
# Extract the columns needed
library(dplyr)
team_predictions <- subset(team_predictions, select = predicted)

# Save all the stuff in one object
write_rds(x = list(team_name, team_people, team_error, team_predictions), 
          path = paste("minitcga_cancer_classification.", team_name, ".rds", sep=""))

```

# Checking format of all saved objects

```{r}

files   <- Sys.glob("minitcga_cancer_classification.*.rds")
results <- tibble(filename = files)

for (i in 1:nrow(results)) {
  x <- read_rds(path = as.character(results$filename[i]))
  results$team_name[i]     <- x[[1]]
  results$team_people[i]   <- paste(x[[2]], collapse=",", sep=" ")
  results$team_error[i]    <- x[[3]]
  y                        <- x[[4]]
  results$n_tumor          <- sum(y$predicted=="Tumor")
  results$n_normal         <- sum(y$predicted=="Normal")
}

rm(x,y)

results %>% select(-filename)

```

# Upload your rds file!
